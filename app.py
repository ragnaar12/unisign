import streamlit as st
import mediapipe as mp
import cv2
import requests
import numpy as np

# Initialisation de Streamlit
st.title("ğŸ–ï¸ UniSign - MVP")
st.write("Ù†Ø¸Ø§Ù… ØªØ±Ø¬Ù…Ø© Ø¨Ø³ÙŠØ· Ù„Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø¨Ù„ØºØ© Ø§Ù„Ø¥Ø´Ø§Ø±Ø©")

# Initialisation de Mediapipe pour la dÃ©tection des mains
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(max_num_hands=1)
mp_draw = mp.solutions.drawing_utils

run = st.checkbox('ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§')

frame_placeholder = st.empty()
label_placeholder = st.empty()

cap = cv2.VideoCapture(0)

# Fonction pour envoyer l'image Ã  DeepAI pour l'analyse
def analyze_image_with_deepai(frame):
    # Convertir l'image en format appropriÃ© pour DeepAI
    _, img_encoded = cv2.imencode('.jpg', frame)
    img_bytes = img_encoded.tobytes()

    # ClÃ© API DeepAI (remplace avec la tienne)
    api_key = 'YOUR_DEEP_AI_API_KEY'

    # URL de l'API DeepAI
    api_url = 'https://api.deepai.org/api/image-recognition'

    headers = {
        'api-key': api_key
    }

    # Envoi de l'image Ã  DeepAI
    response = requests.post(api_url, headers=headers, files={'image': img_bytes})

    if response.status_code == 200:
        result = response.json()
        return result
    else:
        return None

# Fonction pour interprÃ©ter les rÃ©sultats de l'API
def interpret_result(result):
    if result:
        # Par exemple, si DeepAI renvoie des Ã©tiquettes de la reconnaissance d'image
        labels = result.get('output', {}).get('labels', [])
        if labels:
            return f"ğŸ“œ Signification: {', '.join(labels)}"
        else:
            return "ğŸ¤·â€â™‚ï¸ Aucune signification trouvÃ©e"
    else:
        return "ğŸ¤·â€â™‚ï¸ Erreur lors de l'analyse"

# DÃ©tection et interprÃ©tation des gestes
while run:
    ret, frame = cap.read()
    if not ret:
        break
    frame = cv2.flip(frame, 1)
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    result = hands.process(rgb_frame)

    label = "ğŸ‘‹ Ù„Ø§ ÙŠÙˆØ¬Ø¯ ÙŠØ¯"  # Message par dÃ©faut si aucune main n'est dÃ©tectÃ©e

    if result.multi_hand_landmarks:
        for hand_landmarks in result.multi_hand_landmarks:
            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

            # Envoi de l'image pour analyse avec DeepAI
            deepai_result = analyze_image_with_deepai(frame)
            label = interpret_result(deepai_result)

    label_placeholder.markdown(f"### {label}")
    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    frame_placeholder.image(frame, channels="RGB")

cap.release()





